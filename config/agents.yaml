agents:
    - id: email_monitor_agent
      name: Email Monitor Agent
      description: Monitors emails and takes actions based on content
      role: Email Monitoring Specialist
      goal: Monitor inbox for important emails and notify or take actions
      backstory: |
        You are an email monitoring specialist that watches for important messages,
        categorizes them, and takes appropriate actions like flagging urgent items
        or summarizing daily digests.
      tools:
        - mcp_read_google_data
        - mcp_save_episode
        - tool_http_get
      capabilities:
        max_iterations: 10
        verbose: true
      triggers:
        schedule:
            - cron: '*/30 * * * *'
              action: check_emails
        events:
            - type: user_request
              keywords:
                - check emails
                - monitor inbox
                - email summary
            - type: goal
              goal_type: monitor_emails
      behavior:
        thinking_mode: true
        max_retries: 3
        response_format: structured
        use_memory: true
        memory_window: 24h
        prefer_tools: true
        tool_timeout: 60s
      tasks:
        - id: check_unread_emails
          description: Check for unread emails and categorize them
          expected_output: List of unread emails with categories
          tools:
            - mcp_read_google_data
          parameters:
            limit: 50
            query: unread
            type: email
    - id: website_status_monitor
      name: Website Status Monitor
      description: Checks if important websites are up and running, reports their HTTP status codes, and alerts if any are down. Perfect for monitoring critical services or your own infrastructure.
      role: Website Health Monitor
      goal: Monitor a list of websites and report their status (up/down, response times, HTTP status codes) via Telegram
      backstory: |
        You are a website monitoring specialist that checks the health of websites by making HTTP requests
        and analyzing their responses. You provide clear status reports and identify any issues, then notify
        via Telegram for immediate visibility.
      tools:
        - tool_http_get
        - tool_telegram_send
      capabilities:
        max_iterations: 10
        verbose: true
      triggers:
        schedule:
            - cron: '*/15 * * * *'
              action: execute
      behavior:
        thinking_mode: true
        max_retries: 3
        response_format: structured
        use_memory: true
        memory_window: 24h
        prefer_tools: true
        tool_timeout: 60s
      tasks:
        - id: monitor_task
          description: Monitor and check status of websites
          expected_output: Status report for each website (up/down, HTTP status, response time)
          tools:
            - tool_http_get
          parameters:
            websites:
                - https://me.sjfisher.com
                - https://k3s.sjfisher.com
    - id: scraper_agent
      name: Scraper Agent
      description: Intelligent scraper that can plan and execute complex web extractions
      role: Web Scraping Specialist
      goal: Plan and execute web scraping operations to extract specific data from any given URL
      backstory: |
        You are an expert web scraper that uses Playwright and intelligent planning
        to navigate complex websites, handle autocompletes, and extract data accurately.
      tools:
        - smart_scrape
        - tool_http_get
      capabilities:
        max_iterations: 15
        verbose: true
      triggers:
        events:
          - type: user_request
            keywords:
              - scrape
              - extract data
              - find price
              - flight emissions
          - type: goal
            goal_type: scrape_web
      behavior:
        thinking_mode: true
        max_retries: 5
        use_memory: true
        prefer_tools: true
        tool_timeout: 120s

    - id: price_monitor_agent
      name: Price Monitor Agent
      description: Monitors product prices twice daily and alerts on Telegram if prices drop by more than 10%.
      role: Price Watcher & Analyst
      goal: Track a list of product URLs, extract prices, compare with history, and notify on significant price drops.
      backstory: |
        You are a dedicated shopping assistant. You check prices for a specific list of items twice a day.
        You maintain a historical record of prices in 'data/price_history.json'.
        Whenever you run, you compare the current price with the previous one.
        If a price falls by 10% or more, you send an urgent alert via Telegram.
      tools:
        - mcp_smart_scrape
        - tool_telegram_send
        - tool_file_read
        - tool_file_write
      capabilities:
        max_iterations: 15
        verbose: true
      triggers:
        schedule:
            - cron: '0 9,17 * * *'
              action: "Check all watched products for price drops."
      behavior:
        thinking_mode: true
        max_retries: 3
        use_memory: true
        prefer_tools: true
      instructions:
        - "1. Read the current price history from 'config/price_history.json' using tool_file_read."
        - "2. For each product in your watch list, use mcp_smart_scrape with the provided selectors to get the current price."
        - "3. Current Watch List:"
        - "   - Product: ASUS Ascent Laptop, URL: https://www.amazon.fr/-/en/gp/product/B0G1CC2949, Selector: 'div#tp-tool-tip-price-block > div > div'"
        - "4. Compare the new price with the 'last_price' in the history."
        - "5. If the new price is <= 90% of the last_price, send a Telegram alert."
        - "6. Update 'config/price_history.json' with the new prices and the current timestamp."
        - "7. DO NOT use placeholder paths like '/path/to/'. Use 'config/price_history.json' exactly."
