{
  "llm_provider": "local",
  "llm_api_key": "",
  "mcp_endpoint": "mock://localhost:3000/mcp",
  "settings": {
    "model": "llama3.2:latest",
    "temperature": "0.7",
    "max_tokens": "1000",
    "llm_timeout_seconds": "60"
  },
  "server": {
    "port": 8080,
    "host": "localhost"
  }
}
