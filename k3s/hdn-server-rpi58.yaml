apiVersion: apps/v1
kind: Deployment
metadata:
  name: hdn-server-rpi58
  namespace: agi
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hdn-server-rpi58
  template:
    metadata:
      labels:
        app: hdn-server-rpi58
    spec:
      nodeSelector:
        kubernetes.io/hostname: rpi58
      tolerations:
        - key: "node-role.kubernetes.io/control-plane"
          operator: "Exists"
          effect: "NoSchedule"
      containers:
        - name: hdn-server
          image: stevef1uk/hdn-server:secure
          imagePullPolicy: Always
          args: ["--domain", "/config/domain.json", "--config", "/config/config.json", "--port", "8080", "--mode", "server"]
          ports:
            - containerPort: 8080
              name: http
          env:
            - name: QUIET
              value: "1"
            - name: DRONE_TOKEN
              value: "JnFN2PMNrjlb0r85slGbNWfYFGxD68wd"
            - name: DRONE_REPO
              value: "stevef/agi-runtime"
            - name: NEO4J_URI
              value: "bolt://neo4j.agi.svc.cluster.local:7687"
            - name: NEO4J_USER
              value: "neo4j"
            - name: NEO4J_PASS
              value: "test1234"
            - name: REDIS_URL
              value: "redis://redis.agi.svc.cluster.local:6379"
            - name: WEAVIATE_URL
              value: "http://weaviate.agi.svc.cluster.local:8080"
            - name: NATS_URL
              value: "nats://nats.agi.svc.cluster.local:4222"
            - name: PRINCIPLES_URL
              value: "http://principles-server.agi.svc.cluster.local:8080"
            # LLM configuration from secret (can be updated without changing deployment)
            - name: LLM_PROVIDER
              valueFrom:
                secretKeyRef:
                  name: llm-config
                  key: LLM_PROVIDER
            - name: LLM_MODEL
              valueFrom:
                secretKeyRef:
                  name: llm-config
                  key: LLM_MODEL
            - name: LLM_TIMEOUT_SECONDS
              valueFrom:
                secretKeyRef:
                  name: llm-config
                  key: LLM_TIMEOUT_SECONDS
            - name: LLM_TIMEOUT
              valueFrom:
                secretKeyRef:
                  name: llm-config
                  key: LLM_TIMEOUT
            # Use OPENAI_BASE_URL for OpenAI-compatible servers (llama.cpp)
            - name: OPENAI_BASE_URL
              valueFrom:
                secretKeyRef:
                  name: llm-config
                  key: OPENAI_BASE_URL
                  optional: true
            # Fallback: OLLAMA_BASE_URL for Ollama servers
            - name: OLLAMA_BASE_URL
              valueFrom:
                secretKeyRef:
                  name: llm-config
                  key: OLLAMA_BASE_URL
                  optional: true
            - name: HDN_URL
              value: "http://hdn-server-rpi58.agi.svc.cluster.local:8080"
            - name: HDN_NODEPORT
              value: "30257"
            - name: SECURE_CUSTOMER_PRIVATE_PATH
              value: "/keys/customer_private.pem"
            - name: SECURE_VENDOR_TOKEN
              valueFrom:
                secretKeyRef:
                  name: secure-vendor
                  key: token
            - name: N8N_WEBHOOK_SECRET
              valueFrom:
                secretKeyRef:
                  name: secure-vendor
                  key: token
            - name: N8N_WEBHOOK_URL
              value: "http://n8n.n8n.svc.cluster.local:5678/webhook/google-workspace"
            - name: UNPACK_WORK_DIR
              value: "/tmp/unpack"
            # Docker resource limits for Raspberry Pi (increased for code validation)
            - name: DOCKER_MEMORY_LIMIT
              value: "512m"
            - name: DOCKER_CPU_LIMIT
              value: "1.0"
            - name: DOCKER_PIDS_LIMIT
              value: "256"
            - name: DOCKER_TMPFS_SIZE
              value: "128m"
            - name: ENABLE_ARM64_TOOLS
              value: "true"
            - name: EXECUTION_METHOD
              value: "ssh"
            # GPU Optimization: Reduced concurrent execution limits (increased for testing)
            - name: HDN_MAX_CONCURRENT_EXECUTIONS
              value: "10"
            # GPU Optimization: LLM request throttling (prevents GPU overload)
            # Set to 2-3 for RPI to allow background work while limiting GPU load
            - name: LLM_MAX_CONCURRENT_REQUESTS
              valueFrom:
                secretKeyRef:
                  name: llm-config
                  key: LLM_MAX_CONCURRENT_REQUESTS
            # Async LLM Queue Configuration
            - name: USE_ASYNC_LLM_QUEUE
              valueFrom:
                secretKeyRef:
                  name: llm-config
                  key: USE_ASYNC_LLM_QUEUE
            - name: ASYNC_LLM_MAX_WORKERS
              valueFrom:
                secretKeyRef:
                  name: llm-config
                  key: ASYNC_LLM_MAX_WORKERS
            - name: ASYNC_LLM_TIMEOUT_SECONDS
              valueFrom:
                secretKeyRef:
                  name: llm-config
                  key: ASYNC_LLM_TIMEOUT_SECONDS
            # Enable background LLM work (FSM, learning, etc.) - allow background processes
            - name: DISABLE_BACKGROUND_LLM
              value: "0"
            - name: RPI_HOST
              value: "192.168.1.63"
          livenessProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 15
            periodSeconds: 5
            timeoutSeconds: 5
            failureThreshold: 3
          resources:
            requests:
              memory: "512Mi"
              cpu: "200m"
            limits:
              memory: "1Gi"
              cpu: "1000m"
          volumeMounts:
            - name: customer-key
              mountPath: /keys
              readOnly: true
            - name: hdn-config
              mountPath: /config
              readOnly: true
            - name: ssh-keys
              mountPath: /root/.ssh
              readOnly: true
      volumes:
        - name: customer-key
          secret:
            secretName: secure-customer-private
        - name: hdn-config
          configMap:
            name: hdn-config
            items:
              - key: config.json
                path: config.json
              - key: domain.json
                path: domain.json
        - name: ssh-keys
          secret:
            secretName: ssh-keys
            defaultMode: 0600
      securityContext:
        runAsNonRoot: false
        runAsUser: 0
---
apiVersion: v1
kind: Service
metadata:
  name: hdn-server-rpi58
  namespace: agi
spec:
  type: NodePort
  selector:
    app: hdn-server-rpi58
  ports:
    - port: 8080
      targetPort: http
      nodePort: 30257
      name: http
